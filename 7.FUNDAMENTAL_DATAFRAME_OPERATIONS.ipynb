{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22319390-296b-428f-a1f0-301ee6a63b3d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "FUNDAMENTAL DATAFRAME OPERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c832d4-c008-4cd2-a7d4-8b1e25f68efe",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"/?o=1209241429508292#setting/sparkui/1017-204439-19zgysxo/driver-3310234515662252512\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[8]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Databricks Shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"/?o=1209241429508292#setting/sparkui/1017-204439-19zgysxo/driver-3310234515662252512\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.2</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[8]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b5ef3fd7-3400-445c-91a5-c8668f5c2b3b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "FIRST OF ALL YOU NEED TO MAKE A DATAFRAME OR LOAD DF INTO ONE VARIABLE IN ORDER TO DO OPERATIONS ON IT... (pretty basic na?)\n",
    "SO LETS US DO IT!! I'll use same file that i used in LECTURE 1!\n",
    "'''\n",
    "\n",
    "flight_data = spark.read.format(\"csv\")\\\n",
    "  .option(\"inferschema\",\"True\")\\\n",
    "  .option(\"mode\",\"failfast\")\\\n",
    "  .option(\"header\",\"True\")\\\n",
    "  .load(\"/FileStore/tables/flight_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad2fffbd-b581-4e1a-9c8a-b6ebdbad264f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- DEST_COUNTRY_NAME: string (nullable = true)\n |-- ORIGIN_COUNTRY_NAME: string (nullable = true)\n |-- count: integer (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "FIRST WE WILL SEE WHAT DOES OUR SCHEMA LOOK LIKE \n",
    "'''\n",
    "flight_data.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2153b719-0826-4640-844f-04d0c0d95cee",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa6ff200-d56d-47e5-a8ac-ebe56abd66ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n|DEST_COUNTRY_NAME|count|\n+-----------------+-----+\n|    United States|    1|\n|    United States|  264|\n|    United States|   69|\n|            Egypt|   24|\n|Equatorial Guinea|    1|\n+-----------------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here we will try to learn basic select syntax to see columns in a dataframe\n",
    "There are 2 methods where we can select column names from a dataframe.\n",
    "\n",
    "1. use select method\n",
    "Select(\"column_name\",\"column_name\",.... )\n",
    "\n",
    "'''\n",
    "flight_data.select(\"DEST_COUNTRY_NAME\",\"count\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a78184d-f48e-4e62-8af6-5e6209ce8f97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n|DEST_COUNTRY_NAME|count|\n+-----------------+-----+\n|    United States|    1|\n|    United States|  264|\n|    United States|   69|\n|            Egypt|   24|\n|Equatorial Guinea|    1|\n+-----------------+-----+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here we will try to learn basic select syntax to see columns in a dataframe\n",
    "There are 2 methods where we can select column names from a dataframe.\n",
    "\n",
    "2. Use COL method\n",
    "Select(COL(\"Column_name\"),COL(\"column_name\"))\n",
    "'''\n",
    "flight_data.select(col(\"DEST_COUNTRY_NAME\"),col(\"count\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2d715365-d88d-486a-828e-59cf11e754e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "7.FUNDAMENTAL_DATAFRAME_OPERATIONS",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
